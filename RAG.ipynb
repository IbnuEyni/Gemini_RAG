{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading PDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import os\n",
    "os.environ[\"GEMINI_API_KEY\"]=st.secrets[\"GEMINI_API_KEY\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "\n",
    "def load_pdf(file_path):\n",
    "    \"\"\"\n",
    "    Reads the text content from a PDF file and returns it as a single string.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path (str): The file path to the PDF file.\n",
    "\n",
    "    Returns:\n",
    "    - str: The concatenated text content of all pages in the PDF.\n",
    "\n",
    "    Raises:\n",
    "    - FileNotFoundError: If the specified file_path does not exist.\n",
    "    - PyPDF2.utils.PdfReadError: If the PDF file is encrypted or malformed.\n",
    "\n",
    "    Example:\n",
    "    >>> pdf_text = load_pdf(\"example.pdf\") \n",
    "    >>> print(pdf_text)\n",
    "    \"This is the text content extracted from the PDF file.\"\n",
    "    \"\"\"\n",
    "    # Logic to read pdf\n",
    "    reader = PdfReader(file_path)\n",
    "\n",
    "    # Loop over each page and store it in a variable\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text()\n",
    "\n",
    "    return text\n",
    "\n",
    "text = load_pdf(file_path=\"/home/shuaib/Desktop/School/AI_programming/Gemini_RAG/data/state_of_the_union.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_text = load_pdf(file_path=\"/home/shuaib/Desktop/School/AI_programming/Gemini_RAG/data/state_of_the_union.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Function to split the text into chunks\n",
    "def split_text(text: str, chunk_size: int = 10000, chunk_overlap: int = 500):\n",
    "    \"\"\"\n",
    "    Splits a text string into smaller chunks based on sentence boundaries while ensuring\n",
    "    that each chunk does not exceed a specified size. The function also allows for a \n",
    "    slight overlap between chunks to maintain context.\n",
    "\n",
    "    Parameters:\n",
    "    - text (str): The input text to be split.\n",
    "    - chunk_size (int): The maximum size of each chunk in characters (default is 10000).\n",
    "    - chunk_overlap (int): The number of overlapping characters between consecutive chunks (default is 500).\n",
    "\n",
    "    Returns:\n",
    "    - List[str]: A list containing text chunks that do not exceed the specified chunk size.\n",
    "    \"\"\"\n",
    "    # Split text into sentences using regular expressions\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "\n",
    "    # Iterate over sentences and build chunks\n",
    "    for sentence in sentences:\n",
    "        if len(current_chunk) + len(sentence) < chunk_size:\n",
    "            current_chunk += \" \" + sentence\n",
    "        else:\n",
    "            # Add the current chunk to the list and start a new chunk\n",
    "            chunks.append(current_chunk.strip())\n",
    "            current_chunk = sentence\n",
    "\n",
    "    # Add the last chunk if it exists\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk.strip())\n",
    "\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_text = split_text(pdf_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "import os\n",
    "\n",
    "class GeminiEmbeddingFunction(EmbeddingFunction):\n",
    "    \"\"\"\n",
    "    Custom embedding function using the Gemini AI API for document retrieval.\n",
    "\n",
    "    This class extends the EmbeddingFunction class and implements the __call__ method\n",
    "    to generate embeddings for a given set of documents using the Gemini AI API.\n",
    "\n",
    "    Parameters:\n",
    "    - input (Documents): A collection of documents to be embedded.\n",
    "\n",
    "    Returns:\n",
    "    - Embeddings: Embeddings generated for the input documents.\n",
    "\n",
    "    Raises:\n",
    "    - ValueError: If the Gemini API Key is not provided as an environment variable (GEMINI_API_KEY).\n",
    "\n",
    "    Example:\n",
    "    >>> gemini_embedding_function = GeminiEmbeddingFunction()\n",
    "    >>> input_documents = Documents([\"Document 1\", \"Document 2\", \"Document 3\"])\n",
    "    >>> embeddings_result = gemini_embedding_function(input_documents)\n",
    "    >>> print(embeddings_result)\n",
    "    Embeddings for the input documents generated by the Gemini AI API.\n",
    "    \"\"\"\n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "        gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "        if not gemini_api_key:\n",
    "            raise ValueError(\"Gemini API Key not provided. Please provide GEMINI_API_KEY as an environment variable\")\n",
    "        genai.configure(api_key=gemini_api_key)\n",
    "        model = \"models/embedding-001\"\n",
    "        title = \"Custom query\"\n",
    "        return genai.embed_content(model=model,\n",
    "                                   content=input,\n",
    "                                   task_type=\"retrieval_document\",\n",
    "                                   title=title)[\"embedding\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing vectors into DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "UniqueConstraintError",
     "evalue": "Collection rag_experiment already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUniqueConstraintError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 23\u001b[0m\n\u001b[1;32m     19\u001b[0m         db\u001b[38;5;241m.\u001b[39madd(documents\u001b[38;5;241m=\u001b[39md, ids\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(i))\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m db, name\n\u001b[0;32m---> 23\u001b[0m db,name \u001b[38;5;241m=\u001b[39m\u001b[43mcreate_chroma_db\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/shuaib/Desktop/School/AI_programming/RAG/content\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrag_experiment\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 16\u001b[0m, in \u001b[0;36mcreate_chroma_db\u001b[0;34m(documents, path, name)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03mCreates a Chroma database using the provided documents, path, and collection name.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m- Tuple[chromadb.Collection, str]: A tuple containing the created Chroma Collection and its name.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     15\u001b[0m chroma_client \u001b[38;5;241m=\u001b[39m chromadb\u001b[38;5;241m.\u001b[39mPersistentClient(path\u001b[38;5;241m=\u001b[39mpath)\n\u001b[0;32m---> 16\u001b[0m db \u001b[38;5;241m=\u001b[39m \u001b[43mchroma_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mGeminiEmbeddingFunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(documents):\n\u001b[1;32m     19\u001b[0m     db\u001b[38;5;241m.\u001b[39madd(documents\u001b[38;5;241m=\u001b[39md, ids\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(i))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/chromadb/api/client.py:198\u001b[0m, in \u001b[0;36mClient.create_collection\u001b[0;34m(self, name, metadata, embedding_function, data_loader, get_or_create)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_collection\u001b[39m(\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    196\u001b[0m     get_or_create: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    197\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Collection:\n\u001b[0;32m--> 198\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_server\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43membedding_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtenant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mget_or_create\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_or_create\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/chromadb/telemetry/opentelemetry/__init__.py:127\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/chromadb/api/segment.py:166\u001b[0m, in \u001b[0;36mSegmentAPI.create_collection\u001b[0;34m(self, name, metadata, embedding_function, data_loader, get_or_create, tenant, database)\u001b[0m\n\u001b[1;32m    162\u001b[0m check_index_name(name)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m uuid4()\n\u001b[0;32m--> 166\u001b[0m coll, created \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sysdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdimension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[43mget_or_create\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_or_create\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtenant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created:\n\u001b[1;32m    177\u001b[0m     segments \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_manager\u001b[38;5;241m.\u001b[39mcreate_segments(coll)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/chromadb/telemetry/opentelemetry/__init__.py:127\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/chromadb/db/mixins/sysdb.py:225\u001b[0m, in \u001b[0;36mSqlSysDB.create_collection\u001b[0;34m(self, id, name, metadata, dimension, get_or_create, tenant, database)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    219\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_collections(\n\u001b[1;32m    220\u001b[0m                 \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39mcollection[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m], tenant\u001b[38;5;241m=\u001b[39mtenant, database\u001b[38;5;241m=\u001b[39mdatabase\n\u001b[1;32m    221\u001b[0m             )[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    222\u001b[0m             \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    223\u001b[0m         )\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 225\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m UniqueConstraintError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCollection \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m already exists\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    227\u001b[0m topic \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assignment_policy\u001b[38;5;241m.\u001b[39massign_collection(\u001b[38;5;28mid\u001b[39m)\n\u001b[1;32m    228\u001b[0m collection \u001b[38;5;241m=\u001b[39m Collection(\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mid\u001b[39m,\n\u001b[1;32m    230\u001b[0m     topic\u001b[38;5;241m=\u001b[39mtopic,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    235\u001b[0m     database\u001b[38;5;241m=\u001b[39mdatabase,\n\u001b[1;32m    236\u001b[0m )\n",
      "\u001b[0;31mUniqueConstraintError\u001b[0m: Collection rag_experiment already exists"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from typing import List\n",
    "def create_chroma_db(documents:List, path:str, name:str):\n",
    "    \"\"\"\n",
    "    Creates a Chroma database using the provided documents, path, and collection name.\n",
    "\n",
    "    Parameters:\n",
    "    - documents: An iterable of documents to be added to the Chroma database.\n",
    "    - path (str): The path where the Chroma database will be stored.\n",
    "    - name (str): The name of the collection within the Chroma database.\n",
    "\n",
    "    Returns:\n",
    "    - Tuple[chromadb.Collection, str]: A tuple containing the created Chroma Collection and its name.\n",
    "    \"\"\"\n",
    "    chroma_client = chromadb.PersistentClient(path=path)\n",
    "    db = chroma_client.create_collection(name=name, embedding_function=GeminiEmbeddingFunction())\n",
    "\n",
    "    for i, d in enumerate(documents):\n",
    "        db.add(documents=d, ids=str(i))\n",
    "\n",
    "    return db, name\n",
    "\n",
    "db,name =create_chroma_db(documents=chunked_text, \n",
    "                          path=\"/home/shuaib/Desktop/School/AI_programming/RAG/content\",\n",
    "                          name=\"rag_experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "# Function to create or load ChromaDB and store vectors\n",
    "def create_or_load_chroma_db(documents, path: str, name: str):\n",
    "    \"\"\"\n",
    "    Creates or loads a Chroma database collection using the provided documents, path, and collection name.\n",
    "    If the collection already exists, it will be loaded; otherwise, a new collection will be created.\n",
    "\n",
    "    Parameters:\n",
    "    - documents: An iterable of documents to be added to the Chroma database if creating a new collection.\n",
    "    - path (str): The path where the Chroma database will be stored or accessed.\n",
    "    - name (str): The name of the collection within the Chroma database.\n",
    "\n",
    "    Returns:\n",
    "    - Tuple[chromadb.Collection, str]: A tuple containing the Chroma Collection and its name.\n",
    "    \"\"\"\n",
    "    # Initialize ChromaDB client with the specified path\n",
    "    chroma_client = chromadb.PersistentClient(path=path)\n",
    "    \n",
    "    # Get the names of existing collections\n",
    "    existing_collections = chroma_client.list_collections()\n",
    "    collection_names = [collection.name for collection in existing_collections]\n",
    "\n",
    "    # Check if the collection already exists\n",
    "    if name in collection_names:\n",
    "        st.write(f\"Loading existing collection: {name}\")\n",
    "        # Load the existing collection\n",
    "        db = chroma_client.get_collection(name=name, embedding_function=GeminiEmbeddingFunction())\n",
    "    else:\n",
    "        st.write(f\"Creating new collection: {name}\")\n",
    "        # Create a new collection and add the documents\n",
    "        db = chroma_client.create_collection(name=name, embedding_function=GeminiEmbeddingFunction())\n",
    "        for i, d in enumerate(documents):\n",
    "            db.add(documents=d, ids=str(i))\n",
    "    \n",
    "    return db, name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-04 10:57:03.519 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /home/shuaib/.local/lib/python3.10/site-packages/ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "db,name =create_or_load_chroma_db(documents=text, path=\"/home/shuaib/Desktop/School/AI_programming/RAG/content\", name=\"rag_experiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_passage(query: str, db, n_results: int):\n",
    "    \"\"\"\n",
    "    Retrieves the most relevant passage from the database based on the provided query.\n",
    "\n",
    "    Parameters:\n",
    "    - query (str): The search query to find the relevant passage.\n",
    "    - db: The Chroma database collection to query.\n",
    "    - n_results (int): The number of results to retrieve from the query.\n",
    "\n",
    "    Returns:\n",
    "    - str: The most relevant passage based on the query, or an empty string if no relevant passages are found.\n",
    "    \"\"\"\n",
    "    # Query the database with the given search query and number of results\n",
    "    results = db.query(query_texts=[query], n_results=n_results)\n",
    "    \n",
    "    # Extract the most relevant passage from the query results\n",
    "    # If there are no documents found, return an empty string\n",
    "    passage = results['documents'][0] if results['documents'] else \"\"\n",
    "    \n",
    "    return passage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 3 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    }
   ],
   "source": [
    "relevant_text = get_relevant_passage(\"Sanctions on Russia\",db,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "def generate_response(query: str, relevant_passages: list):\n",
    "    \"\"\"\n",
    "    Generates a detailed response to a query based on provided relevant passages using the Gemini AI model.\n",
    "\n",
    "    Parameters:\n",
    "    - query (str): The question or query that needs to be answered.\n",
    "    - relevant_passages (list): A list of relevant passages or context to use for generating the response.\n",
    "\n",
    "    Returns:\n",
    "    - str: The generated response from the Gemini AI model.\n",
    "    \"\"\"\n",
    "    # Retrieve the Gemini API key from environment variables\n",
    "    gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "    if not gemini_api_key:\n",
    "        raise ValueError(\"Gemini API Key not provided. Please provide GEMINI_API_KEY as an environment variable\")\n",
    "    \n",
    "    # Configure the generative AI model with the provided API key\n",
    "    genai.configure(api_key=gemini_api_key)\n",
    "    model = genai.GenerativeModel('gemini-pro')\n",
    "    \n",
    "    # Combine relevant passages into a single context block\n",
    "    context = \"\\n\\n\".join(relevant_passages)\n",
    "    \n",
    "    # Create a prompt template that includes the context and the query\n",
    "    prompt_template = f\"\"\"\n",
    "    Answer the question as detailed as possible from the provided context,\n",
    "    making sure to provide all the details. If the answer is not in the provided context, \n",
    "    just say, \"The answer is not available in the context.\"\n",
    "    \n",
    "    Context:\n",
    "    {context}\n",
    "    \n",
    "    Question:\n",
    "    {query}\n",
    "    \n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate the content using the AI model based on the prompt template\n",
    "    answer = model.generate_content(prompt_template)\n",
    "    \n",
    "    return answer.text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bringing it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_answer(db,query    ):\n",
    "    #retrieve top 3 relevant text chunks\n",
    "    relevant_text = get_relevant_passage(query,db,n_results=3)\n",
    "    answer = generate_response(query, relevant_text)\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "db, _ =create_or_load_chroma_db(documents=text, path=\"/home/shuaib/Desktop/School/AI_programming/Gemini_RAG/content\", name=\"rag_experiment\")\n",
    "answer = generate_answer(db, query=\"Sanctions on Russia\")\n",
    "print(answer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
